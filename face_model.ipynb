{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.iresnet import iresnet50\n",
    "from models.evidential import edl_mse_loss, edl_digamma_loss, edl_log_loss, relu_evidence, exp_evidence, get_device, one_hot_embedding\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGFace2\n",
    "num_classes = 8631\n",
    "pre_trained = \"ckpt/ArcFace-VGGFace2-R50-8631.pth\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGFace2\n",
    "num_classes = 10177\n",
    "pre_trained = \"ckpt/ArcFace-CelebA-R50-10177.pth\"\n",
    "device = \"cuda:0\"\n",
    "img_path = \"motivation/images/Celeb-A/ID/32/000492.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameter weight\n",
      "Load parameter conv1.weight\n",
      "Load parameter bn1.weight\n",
      "Load parameter bn1.bias\n",
      "Load parameter bn1.running_mean\n",
      "Load parameter bn1.running_var\n",
      "Load parameter bn1.num_batches_tracked\n",
      "Load parameter prelu.weight\n",
      "Load parameter layer1.0.bn1.weight\n",
      "Load parameter layer1.0.bn1.bias\n",
      "Load parameter layer1.0.bn1.running_mean\n",
      "Load parameter layer1.0.bn1.running_var\n",
      "Load parameter layer1.0.bn1.num_batches_tracked\n",
      "Load parameter layer1.0.conv1.weight\n",
      "Load parameter layer1.0.bn2.weight\n",
      "Load parameter layer1.0.bn2.bias\n",
      "Load parameter layer1.0.bn2.running_mean\n",
      "Load parameter layer1.0.bn2.running_var\n",
      "Load parameter layer1.0.bn2.num_batches_tracked\n",
      "Load parameter layer1.0.prelu.weight\n",
      "Load parameter layer1.0.conv2.weight\n",
      "Load parameter layer1.0.bn3.weight\n",
      "Load parameter layer1.0.bn3.bias\n",
      "Load parameter layer1.0.bn3.running_mean\n",
      "Load parameter layer1.0.bn3.running_var\n",
      "Load parameter layer1.0.bn3.num_batches_tracked\n",
      "Load parameter layer1.0.downsample.0.weight\n",
      "Load parameter layer1.0.downsample.1.weight\n",
      "Load parameter layer1.0.downsample.1.bias\n",
      "Load parameter layer1.0.downsample.1.running_mean\n",
      "Load parameter layer1.0.downsample.1.running_var\n",
      "Load parameter layer1.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer1.1.bn1.weight\n",
      "Load parameter layer1.1.bn1.bias\n",
      "Load parameter layer1.1.bn1.running_mean\n",
      "Load parameter layer1.1.bn1.running_var\n",
      "Load parameter layer1.1.bn1.num_batches_tracked\n",
      "Load parameter layer1.1.conv1.weight\n",
      "Load parameter layer1.1.bn2.weight\n",
      "Load parameter layer1.1.bn2.bias\n",
      "Load parameter layer1.1.bn2.running_mean\n",
      "Load parameter layer1.1.bn2.running_var\n",
      "Load parameter layer1.1.bn2.num_batches_tracked\n",
      "Load parameter layer1.1.prelu.weight\n",
      "Load parameter layer1.1.conv2.weight\n",
      "Load parameter layer1.1.bn3.weight\n",
      "Load parameter layer1.1.bn3.bias\n",
      "Load parameter layer1.1.bn3.running_mean\n",
      "Load parameter layer1.1.bn3.running_var\n",
      "Load parameter layer1.1.bn3.num_batches_tracked\n",
      "Load parameter layer1.2.bn1.weight\n",
      "Load parameter layer1.2.bn1.bias\n",
      "Load parameter layer1.2.bn1.running_mean\n",
      "Load parameter layer1.2.bn1.running_var\n",
      "Load parameter layer1.2.bn1.num_batches_tracked\n",
      "Load parameter layer1.2.conv1.weight\n",
      "Load parameter layer1.2.bn2.weight\n",
      "Load parameter layer1.2.bn2.bias\n",
      "Load parameter layer1.2.bn2.running_mean\n",
      "Load parameter layer1.2.bn2.running_var\n",
      "Load parameter layer1.2.bn2.num_batches_tracked\n",
      "Load parameter layer1.2.prelu.weight\n",
      "Load parameter layer1.2.conv2.weight\n",
      "Load parameter layer1.2.bn3.weight\n",
      "Load parameter layer1.2.bn3.bias\n",
      "Load parameter layer1.2.bn3.running_mean\n",
      "Load parameter layer1.2.bn3.running_var\n",
      "Load parameter layer1.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.bn1.weight\n",
      "Load parameter layer2.0.bn1.bias\n",
      "Load parameter layer2.0.bn1.running_mean\n",
      "Load parameter layer2.0.bn1.running_var\n",
      "Load parameter layer2.0.bn1.num_batches_tracked\n",
      "Load parameter layer2.0.conv1.weight\n",
      "Load parameter layer2.0.bn2.weight\n",
      "Load parameter layer2.0.bn2.bias\n",
      "Load parameter layer2.0.bn2.running_mean\n",
      "Load parameter layer2.0.bn2.running_var\n",
      "Load parameter layer2.0.bn2.num_batches_tracked\n",
      "Load parameter layer2.0.prelu.weight\n",
      "Load parameter layer2.0.conv2.weight\n",
      "Load parameter layer2.0.bn3.weight\n",
      "Load parameter layer2.0.bn3.bias\n",
      "Load parameter layer2.0.bn3.running_mean\n",
      "Load parameter layer2.0.bn3.running_var\n",
      "Load parameter layer2.0.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.downsample.0.weight\n",
      "Load parameter layer2.0.downsample.1.weight\n",
      "Load parameter layer2.0.downsample.1.bias\n",
      "Load parameter layer2.0.downsample.1.running_mean\n",
      "Load parameter layer2.0.downsample.1.running_var\n",
      "Load parameter layer2.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer2.1.bn1.weight\n",
      "Load parameter layer2.1.bn1.bias\n",
      "Load parameter layer2.1.bn1.running_mean\n",
      "Load parameter layer2.1.bn1.running_var\n",
      "Load parameter layer2.1.bn1.num_batches_tracked\n",
      "Load parameter layer2.1.conv1.weight\n",
      "Load parameter layer2.1.bn2.weight\n",
      "Load parameter layer2.1.bn2.bias\n",
      "Load parameter layer2.1.bn2.running_mean\n",
      "Load parameter layer2.1.bn2.running_var\n",
      "Load parameter layer2.1.bn2.num_batches_tracked\n",
      "Load parameter layer2.1.prelu.weight\n",
      "Load parameter layer2.1.conv2.weight\n",
      "Load parameter layer2.1.bn3.weight\n",
      "Load parameter layer2.1.bn3.bias\n",
      "Load parameter layer2.1.bn3.running_mean\n",
      "Load parameter layer2.1.bn3.running_var\n",
      "Load parameter layer2.1.bn3.num_batches_tracked\n",
      "Load parameter layer2.2.bn1.weight\n",
      "Load parameter layer2.2.bn1.bias\n",
      "Load parameter layer2.2.bn1.running_mean\n",
      "Load parameter layer2.2.bn1.running_var\n",
      "Load parameter layer2.2.bn1.num_batches_tracked\n",
      "Load parameter layer2.2.conv1.weight\n",
      "Load parameter layer2.2.bn2.weight\n",
      "Load parameter layer2.2.bn2.bias\n",
      "Load parameter layer2.2.bn2.running_mean\n",
      "Load parameter layer2.2.bn2.running_var\n",
      "Load parameter layer2.2.bn2.num_batches_tracked\n",
      "Load parameter layer2.2.prelu.weight\n",
      "Load parameter layer2.2.conv2.weight\n",
      "Load parameter layer2.2.bn3.weight\n",
      "Load parameter layer2.2.bn3.bias\n",
      "Load parameter layer2.2.bn3.running_mean\n",
      "Load parameter layer2.2.bn3.running_var\n",
      "Load parameter layer2.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.3.bn1.weight\n",
      "Load parameter layer2.3.bn1.bias\n",
      "Load parameter layer2.3.bn1.running_mean\n",
      "Load parameter layer2.3.bn1.running_var\n",
      "Load parameter layer2.3.bn1.num_batches_tracked\n",
      "Load parameter layer2.3.conv1.weight\n",
      "Load parameter layer2.3.bn2.weight\n",
      "Load parameter layer2.3.bn2.bias\n",
      "Load parameter layer2.3.bn2.running_mean\n",
      "Load parameter layer2.3.bn2.running_var\n",
      "Load parameter layer2.3.bn2.num_batches_tracked\n",
      "Load parameter layer2.3.prelu.weight\n",
      "Load parameter layer2.3.conv2.weight\n",
      "Load parameter layer2.3.bn3.weight\n",
      "Load parameter layer2.3.bn3.bias\n",
      "Load parameter layer2.3.bn3.running_mean\n",
      "Load parameter layer2.3.bn3.running_var\n",
      "Load parameter layer2.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.bn1.weight\n",
      "Load parameter layer3.0.bn1.bias\n",
      "Load parameter layer3.0.bn1.running_mean\n",
      "Load parameter layer3.0.bn1.running_var\n",
      "Load parameter layer3.0.bn1.num_batches_tracked\n",
      "Load parameter layer3.0.conv1.weight\n",
      "Load parameter layer3.0.bn2.weight\n",
      "Load parameter layer3.0.bn2.bias\n",
      "Load parameter layer3.0.bn2.running_mean\n",
      "Load parameter layer3.0.bn2.running_var\n",
      "Load parameter layer3.0.bn2.num_batches_tracked\n",
      "Load parameter layer3.0.prelu.weight\n",
      "Load parameter layer3.0.conv2.weight\n",
      "Load parameter layer3.0.bn3.weight\n",
      "Load parameter layer3.0.bn3.bias\n",
      "Load parameter layer3.0.bn3.running_mean\n",
      "Load parameter layer3.0.bn3.running_var\n",
      "Load parameter layer3.0.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.downsample.0.weight\n",
      "Load parameter layer3.0.downsample.1.weight\n",
      "Load parameter layer3.0.downsample.1.bias\n",
      "Load parameter layer3.0.downsample.1.running_mean\n",
      "Load parameter layer3.0.downsample.1.running_var\n",
      "Load parameter layer3.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer3.1.bn1.weight\n",
      "Load parameter layer3.1.bn1.bias\n",
      "Load parameter layer3.1.bn1.running_mean\n",
      "Load parameter layer3.1.bn1.running_var\n",
      "Load parameter layer3.1.bn1.num_batches_tracked\n",
      "Load parameter layer3.1.conv1.weight\n",
      "Load parameter layer3.1.bn2.weight\n",
      "Load parameter layer3.1.bn2.bias\n",
      "Load parameter layer3.1.bn2.running_mean\n",
      "Load parameter layer3.1.bn2.running_var\n",
      "Load parameter layer3.1.bn2.num_batches_tracked\n",
      "Load parameter layer3.1.prelu.weight\n",
      "Load parameter layer3.1.conv2.weight\n",
      "Load parameter layer3.1.bn3.weight\n",
      "Load parameter layer3.1.bn3.bias\n",
      "Load parameter layer3.1.bn3.running_mean\n",
      "Load parameter layer3.1.bn3.running_var\n",
      "Load parameter layer3.1.bn3.num_batches_tracked\n",
      "Load parameter layer3.2.bn1.weight\n",
      "Load parameter layer3.2.bn1.bias\n",
      "Load parameter layer3.2.bn1.running_mean\n",
      "Load parameter layer3.2.bn1.running_var\n",
      "Load parameter layer3.2.bn1.num_batches_tracked\n",
      "Load parameter layer3.2.conv1.weight\n",
      "Load parameter layer3.2.bn2.weight\n",
      "Load parameter layer3.2.bn2.bias\n",
      "Load parameter layer3.2.bn2.running_mean\n",
      "Load parameter layer3.2.bn2.running_var\n",
      "Load parameter layer3.2.bn2.num_batches_tracked\n",
      "Load parameter layer3.2.prelu.weight\n",
      "Load parameter layer3.2.conv2.weight\n",
      "Load parameter layer3.2.bn3.weight\n",
      "Load parameter layer3.2.bn3.bias\n",
      "Load parameter layer3.2.bn3.running_mean\n",
      "Load parameter layer3.2.bn3.running_var\n",
      "Load parameter layer3.2.bn3.num_batches_tracked\n",
      "Load parameter layer3.3.bn1.weight\n",
      "Load parameter layer3.3.bn1.bias\n",
      "Load parameter layer3.3.bn1.running_mean\n",
      "Load parameter layer3.3.bn1.running_var\n",
      "Load parameter layer3.3.bn1.num_batches_tracked\n",
      "Load parameter layer3.3.conv1.weight\n",
      "Load parameter layer3.3.bn2.weight\n",
      "Load parameter layer3.3.bn2.bias\n",
      "Load parameter layer3.3.bn2.running_mean\n",
      "Load parameter layer3.3.bn2.running_var\n",
      "Load parameter layer3.3.bn2.num_batches_tracked\n",
      "Load parameter layer3.3.prelu.weight\n",
      "Load parameter layer3.3.conv2.weight\n",
      "Load parameter layer3.3.bn3.weight\n",
      "Load parameter layer3.3.bn3.bias\n",
      "Load parameter layer3.3.bn3.running_mean\n",
      "Load parameter layer3.3.bn3.running_var\n",
      "Load parameter layer3.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.4.bn1.weight\n",
      "Load parameter layer3.4.bn1.bias\n",
      "Load parameter layer3.4.bn1.running_mean\n",
      "Load parameter layer3.4.bn1.running_var\n",
      "Load parameter layer3.4.bn1.num_batches_tracked\n",
      "Load parameter layer3.4.conv1.weight\n",
      "Load parameter layer3.4.bn2.weight\n",
      "Load parameter layer3.4.bn2.bias\n",
      "Load parameter layer3.4.bn2.running_mean\n",
      "Load parameter layer3.4.bn2.running_var\n",
      "Load parameter layer3.4.bn2.num_batches_tracked\n",
      "Load parameter layer3.4.prelu.weight\n",
      "Load parameter layer3.4.conv2.weight\n",
      "Load parameter layer3.4.bn3.weight\n",
      "Load parameter layer3.4.bn3.bias\n",
      "Load parameter layer3.4.bn3.running_mean\n",
      "Load parameter layer3.4.bn3.running_var\n",
      "Load parameter layer3.4.bn3.num_batches_tracked\n",
      "Load parameter layer3.5.bn1.weight\n",
      "Load parameter layer3.5.bn1.bias\n",
      "Load parameter layer3.5.bn1.running_mean\n",
      "Load parameter layer3.5.bn1.running_var\n",
      "Load parameter layer3.5.bn1.num_batches_tracked\n",
      "Load parameter layer3.5.conv1.weight\n",
      "Load parameter layer3.5.bn2.weight\n",
      "Load parameter layer3.5.bn2.bias\n",
      "Load parameter layer3.5.bn2.running_mean\n",
      "Load parameter layer3.5.bn2.running_var\n",
      "Load parameter layer3.5.bn2.num_batches_tracked\n",
      "Load parameter layer3.5.prelu.weight\n",
      "Load parameter layer3.5.conv2.weight\n",
      "Load parameter layer3.5.bn3.weight\n",
      "Load parameter layer3.5.bn3.bias\n",
      "Load parameter layer3.5.bn3.running_mean\n",
      "Load parameter layer3.5.bn3.running_var\n",
      "Load parameter layer3.5.bn3.num_batches_tracked\n",
      "Load parameter layer3.6.bn1.weight\n",
      "Load parameter layer3.6.bn1.bias\n",
      "Load parameter layer3.6.bn1.running_mean\n",
      "Load parameter layer3.6.bn1.running_var\n",
      "Load parameter layer3.6.bn1.num_batches_tracked\n",
      "Load parameter layer3.6.conv1.weight\n",
      "Load parameter layer3.6.bn2.weight\n",
      "Load parameter layer3.6.bn2.bias\n",
      "Load parameter layer3.6.bn2.running_mean\n",
      "Load parameter layer3.6.bn2.running_var\n",
      "Load parameter layer3.6.bn2.num_batches_tracked\n",
      "Load parameter layer3.6.prelu.weight\n",
      "Load parameter layer3.6.conv2.weight\n",
      "Load parameter layer3.6.bn3.weight\n",
      "Load parameter layer3.6.bn3.bias\n",
      "Load parameter layer3.6.bn3.running_mean\n",
      "Load parameter layer3.6.bn3.running_var\n",
      "Load parameter layer3.6.bn3.num_batches_tracked\n",
      "Load parameter layer3.7.bn1.weight\n",
      "Load parameter layer3.7.bn1.bias\n",
      "Load parameter layer3.7.bn1.running_mean\n",
      "Load parameter layer3.7.bn1.running_var\n",
      "Load parameter layer3.7.bn1.num_batches_tracked\n",
      "Load parameter layer3.7.conv1.weight\n",
      "Load parameter layer3.7.bn2.weight\n",
      "Load parameter layer3.7.bn2.bias\n",
      "Load parameter layer3.7.bn2.running_mean\n",
      "Load parameter layer3.7.bn2.running_var\n",
      "Load parameter layer3.7.bn2.num_batches_tracked\n",
      "Load parameter layer3.7.prelu.weight\n",
      "Load parameter layer3.7.conv2.weight\n",
      "Load parameter layer3.7.bn3.weight\n",
      "Load parameter layer3.7.bn3.bias\n",
      "Load parameter layer3.7.bn3.running_mean\n",
      "Load parameter layer3.7.bn3.running_var\n",
      "Load parameter layer3.7.bn3.num_batches_tracked\n",
      "Load parameter layer3.8.bn1.weight\n",
      "Load parameter layer3.8.bn1.bias\n",
      "Load parameter layer3.8.bn1.running_mean\n",
      "Load parameter layer3.8.bn1.running_var\n",
      "Load parameter layer3.8.bn1.num_batches_tracked\n",
      "Load parameter layer3.8.conv1.weight\n",
      "Load parameter layer3.8.bn2.weight\n",
      "Load parameter layer3.8.bn2.bias\n",
      "Load parameter layer3.8.bn2.running_mean\n",
      "Load parameter layer3.8.bn2.running_var\n",
      "Load parameter layer3.8.bn2.num_batches_tracked\n",
      "Load parameter layer3.8.prelu.weight\n",
      "Load parameter layer3.8.conv2.weight\n",
      "Load parameter layer3.8.bn3.weight\n",
      "Load parameter layer3.8.bn3.bias\n",
      "Load parameter layer3.8.bn3.running_mean\n",
      "Load parameter layer3.8.bn3.running_var\n",
      "Load parameter layer3.8.bn3.num_batches_tracked\n",
      "Load parameter layer3.9.bn1.weight\n",
      "Load parameter layer3.9.bn1.bias\n",
      "Load parameter layer3.9.bn1.running_mean\n",
      "Load parameter layer3.9.bn1.running_var\n",
      "Load parameter layer3.9.bn1.num_batches_tracked\n",
      "Load parameter layer3.9.conv1.weight\n",
      "Load parameter layer3.9.bn2.weight\n",
      "Load parameter layer3.9.bn2.bias\n",
      "Load parameter layer3.9.bn2.running_mean\n",
      "Load parameter layer3.9.bn2.running_var\n",
      "Load parameter layer3.9.bn2.num_batches_tracked\n",
      "Load parameter layer3.9.prelu.weight\n",
      "Load parameter layer3.9.conv2.weight\n",
      "Load parameter layer3.9.bn3.weight\n",
      "Load parameter layer3.9.bn3.bias\n",
      "Load parameter layer3.9.bn3.running_mean\n",
      "Load parameter layer3.9.bn3.running_var\n",
      "Load parameter layer3.9.bn3.num_batches_tracked\n",
      "Load parameter layer3.10.bn1.weight\n",
      "Load parameter layer3.10.bn1.bias\n",
      "Load parameter layer3.10.bn1.running_mean\n",
      "Load parameter layer3.10.bn1.running_var\n",
      "Load parameter layer3.10.bn1.num_batches_tracked\n",
      "Load parameter layer3.10.conv1.weight\n",
      "Load parameter layer3.10.bn2.weight\n",
      "Load parameter layer3.10.bn2.bias\n",
      "Load parameter layer3.10.bn2.running_mean\n",
      "Load parameter layer3.10.bn2.running_var\n",
      "Load parameter layer3.10.bn2.num_batches_tracked\n",
      "Load parameter layer3.10.prelu.weight\n",
      "Load parameter layer3.10.conv2.weight\n",
      "Load parameter layer3.10.bn3.weight\n",
      "Load parameter layer3.10.bn3.bias\n",
      "Load parameter layer3.10.bn3.running_mean\n",
      "Load parameter layer3.10.bn3.running_var\n",
      "Load parameter layer3.10.bn3.num_batches_tracked\n",
      "Load parameter layer3.11.bn1.weight\n",
      "Load parameter layer3.11.bn1.bias\n",
      "Load parameter layer3.11.bn1.running_mean\n",
      "Load parameter layer3.11.bn1.running_var\n",
      "Load parameter layer3.11.bn1.num_batches_tracked\n",
      "Load parameter layer3.11.conv1.weight\n",
      "Load parameter layer3.11.bn2.weight\n",
      "Load parameter layer3.11.bn2.bias\n",
      "Load parameter layer3.11.bn2.running_mean\n",
      "Load parameter layer3.11.bn2.running_var\n",
      "Load parameter layer3.11.bn2.num_batches_tracked\n",
      "Load parameter layer3.11.prelu.weight\n",
      "Load parameter layer3.11.conv2.weight\n",
      "Load parameter layer3.11.bn3.weight\n",
      "Load parameter layer3.11.bn3.bias\n",
      "Load parameter layer3.11.bn3.running_mean\n",
      "Load parameter layer3.11.bn3.running_var\n",
      "Load parameter layer3.11.bn3.num_batches_tracked\n",
      "Load parameter layer3.12.bn1.weight\n",
      "Load parameter layer3.12.bn1.bias\n",
      "Load parameter layer3.12.bn1.running_mean\n",
      "Load parameter layer3.12.bn1.running_var\n",
      "Load parameter layer3.12.bn1.num_batches_tracked\n",
      "Load parameter layer3.12.conv1.weight\n",
      "Load parameter layer3.12.bn2.weight\n",
      "Load parameter layer3.12.bn2.bias\n",
      "Load parameter layer3.12.bn2.running_mean\n",
      "Load parameter layer3.12.bn2.running_var\n",
      "Load parameter layer3.12.bn2.num_batches_tracked\n",
      "Load parameter layer3.12.prelu.weight\n",
      "Load parameter layer3.12.conv2.weight\n",
      "Load parameter layer3.12.bn3.weight\n",
      "Load parameter layer3.12.bn3.bias\n",
      "Load parameter layer3.12.bn3.running_mean\n",
      "Load parameter layer3.12.bn3.running_var\n",
      "Load parameter layer3.12.bn3.num_batches_tracked\n",
      "Load parameter layer3.13.bn1.weight\n",
      "Load parameter layer3.13.bn1.bias\n",
      "Load parameter layer3.13.bn1.running_mean\n",
      "Load parameter layer3.13.bn1.running_var\n",
      "Load parameter layer3.13.bn1.num_batches_tracked\n",
      "Load parameter layer3.13.conv1.weight\n",
      "Load parameter layer3.13.bn2.weight\n",
      "Load parameter layer3.13.bn2.bias\n",
      "Load parameter layer3.13.bn2.running_mean\n",
      "Load parameter layer3.13.bn2.running_var\n",
      "Load parameter layer3.13.bn2.num_batches_tracked\n",
      "Load parameter layer3.13.prelu.weight\n",
      "Load parameter layer3.13.conv2.weight\n",
      "Load parameter layer3.13.bn3.weight\n",
      "Load parameter layer3.13.bn3.bias\n",
      "Load parameter layer3.13.bn3.running_mean\n",
      "Load parameter layer3.13.bn3.running_var\n",
      "Load parameter layer3.13.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.bn1.weight\n",
      "Load parameter layer4.0.bn1.bias\n",
      "Load parameter layer4.0.bn1.running_mean\n",
      "Load parameter layer4.0.bn1.running_var\n",
      "Load parameter layer4.0.bn1.num_batches_tracked\n",
      "Load parameter layer4.0.conv1.weight\n",
      "Load parameter layer4.0.bn2.weight\n",
      "Load parameter layer4.0.bn2.bias\n",
      "Load parameter layer4.0.bn2.running_mean\n",
      "Load parameter layer4.0.bn2.running_var\n",
      "Load parameter layer4.0.bn2.num_batches_tracked\n",
      "Load parameter layer4.0.prelu.weight\n",
      "Load parameter layer4.0.conv2.weight\n",
      "Load parameter layer4.0.bn3.weight\n",
      "Load parameter layer4.0.bn3.bias\n",
      "Load parameter layer4.0.bn3.running_mean\n",
      "Load parameter layer4.0.bn3.running_var\n",
      "Load parameter layer4.0.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.downsample.0.weight\n",
      "Load parameter layer4.0.downsample.1.weight\n",
      "Load parameter layer4.0.downsample.1.bias\n",
      "Load parameter layer4.0.downsample.1.running_mean\n",
      "Load parameter layer4.0.downsample.1.running_var\n",
      "Load parameter layer4.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer4.1.bn1.weight\n",
      "Load parameter layer4.1.bn1.bias\n",
      "Load parameter layer4.1.bn1.running_mean\n",
      "Load parameter layer4.1.bn1.running_var\n",
      "Load parameter layer4.1.bn1.num_batches_tracked\n",
      "Load parameter layer4.1.conv1.weight\n",
      "Load parameter layer4.1.bn2.weight\n",
      "Load parameter layer4.1.bn2.bias\n",
      "Load parameter layer4.1.bn2.running_mean\n",
      "Load parameter layer4.1.bn2.running_var\n",
      "Load parameter layer4.1.bn2.num_batches_tracked\n",
      "Load parameter layer4.1.prelu.weight\n",
      "Load parameter layer4.1.conv2.weight\n",
      "Load parameter layer4.1.bn3.weight\n",
      "Load parameter layer4.1.bn3.bias\n",
      "Load parameter layer4.1.bn3.running_mean\n",
      "Load parameter layer4.1.bn3.running_var\n",
      "Load parameter layer4.1.bn3.num_batches_tracked\n",
      "Load parameter layer4.2.bn1.weight\n",
      "Load parameter layer4.2.bn1.bias\n",
      "Load parameter layer4.2.bn1.running_mean\n",
      "Load parameter layer4.2.bn1.running_var\n",
      "Load parameter layer4.2.bn1.num_batches_tracked\n",
      "Load parameter layer4.2.conv1.weight\n",
      "Load parameter layer4.2.bn2.weight\n",
      "Load parameter layer4.2.bn2.bias\n",
      "Load parameter layer4.2.bn2.running_mean\n",
      "Load parameter layer4.2.bn2.running_var\n",
      "Load parameter layer4.2.bn2.num_batches_tracked\n",
      "Load parameter layer4.2.prelu.weight\n",
      "Load parameter layer4.2.conv2.weight\n",
      "Load parameter layer4.2.bn3.weight\n",
      "Load parameter layer4.2.bn3.bias\n",
      "Load parameter layer4.2.bn3.running_mean\n",
      "Load parameter layer4.2.bn3.running_var\n",
      "Load parameter layer4.2.bn3.num_batches_tracked\n",
      "Load parameter bn2.weight\n",
      "Load parameter bn2.bias\n",
      "Load parameter bn2.running_mean\n",
      "Load parameter bn2.running_var\n",
      "Load parameter bn2.num_batches_tracked\n",
      "Load parameter fc.weight\n",
      "Load parameter fc.bias\n",
      "Load parameter features.weight\n",
      "Load parameter features.bias\n",
      "Load parameter features.running_mean\n",
      "Load parameter features.running_var\n",
      "Load parameter features.num_batches_tracked\n",
      "Success load pre-trained model ckpt/ArcFace-CelebA-R50-10177.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (prelu): PReLU(num_parameters=64)\n",
       "  (layer1): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0, inplace=True)\n",
       "  (fc): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (features): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = iresnet50(num_classes)\n",
    "if pre_trained is not None and os.path.exists(pre_trained):\n",
    "    # No related\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_param = torch.load(pre_trained)\n",
    "    try:\n",
    "        pretrained_param = pretrained_param.state_dict()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in pretrained_param.items():\n",
    "        if k in model_dict:\n",
    "            new_state_dict[k] = v\n",
    "            print(\"Load parameter {}\".format(k))\n",
    "        elif k[7:] in model_dict:\n",
    "            new_state_dict[k[7:]] = v\n",
    "            print(\"Load parameter {}\".format(k[7:]))\n",
    "        # else:\n",
    "        #     print(\"Parameter {} unload.\".format(k[7:]))\n",
    "\n",
    "    model_dict.update(new_state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(\"Success load pre-trained model {}\".format(pre_trained))\n",
    "else:\n",
    "    print(\"not load pretrained\")\n",
    "\n",
    "# Set to device\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "            transforms.Resize((112,112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)\n",
    "img = transforms(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0283,  0.0166,  0.0308,  ..., -0.0678, -0.0817,  0.0233]],\n",
       "       device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.to(device)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  #批处理大小\n",
    "input_shape = (3, 112, 112)   #输入数据,改成自己的输入shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, *input_shape)   # 生成张量\n",
    "x = x.to(device)\n",
    "export_onnx_file = pre_trained.replace(\".pth\", \".onnx\")\t\t# 目的ONNX文件名\n",
    "torch.onnx.export(model,\n",
    "                    x,\n",
    "                    export_onnx_file,\n",
    "                    opset_version=10,\n",
    "                    do_constant_folding=True,\t# 是否执行常量折叠优化\n",
    "                    input_names=[\"input\"],\t# 输入名\n",
    "                    output_names=[\"output\"],\t# 输出名\n",
    "                    dynamic_axes={\"input\":{0:\"batch_size\"},  # 批处理变量\n",
    "                                    \"output\":{0:\"batch_size\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 17:07:01.283868: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-28 17:07:01.329293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 17:07:02.021985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import onnx_tf.backend\n",
    "import onnx\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "            transforms.Resize((112,112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"motivation/images/Celeb-A/ID/32/000492.jpg\"\n",
    "model_path = \"ckpt/ArcFace-CelebA-R50-10177.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)\n",
    "img = np.array([transforms(img).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 17:07:38.027694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] Ignoring visible gpu device (device: 1, name: Quadro K620, pci bus id: 0000:17:00.0, compute capability: 5.0) with core count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2023-04-28 17:07:38.672074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21580 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(model_path)\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model, device='GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 17:07:49.730604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-28 17:07:50.896870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "result = tf_model.run(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.argsort(result[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02835666,  0.0165917 ,  0.03075849, ..., -0.06780577,\n",
       "        -0.08168626,  0.02329685]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
