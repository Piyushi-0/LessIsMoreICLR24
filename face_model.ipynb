{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.iresnet import iresnet50\n",
    "from models.evidential import edl_mse_loss, edl_digamma_loss, edl_log_loss, relu_evidence, exp_evidence, get_device, one_hot_embedding\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8631\n",
    "pre_trained = \"ckpt/ArcFace-8631.pth\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameter weight\n",
      "Load parameter conv1.weight\n",
      "Load parameter bn1.weight\n",
      "Load parameter bn1.bias\n",
      "Load parameter bn1.running_mean\n",
      "Load parameter bn1.running_var\n",
      "Load parameter bn1.num_batches_tracked\n",
      "Load parameter prelu.weight\n",
      "Load parameter layer1.0.bn1.weight\n",
      "Load parameter layer1.0.bn1.bias\n",
      "Load parameter layer1.0.bn1.running_mean\n",
      "Load parameter layer1.0.bn1.running_var\n",
      "Load parameter layer1.0.bn1.num_batches_tracked\n",
      "Load parameter layer1.0.conv1.weight\n",
      "Load parameter layer1.0.bn2.weight\n",
      "Load parameter layer1.0.bn2.bias\n",
      "Load parameter layer1.0.bn2.running_mean\n",
      "Load parameter layer1.0.bn2.running_var\n",
      "Load parameter layer1.0.bn2.num_batches_tracked\n",
      "Load parameter layer1.0.prelu.weight\n",
      "Load parameter layer1.0.conv2.weight\n",
      "Load parameter layer1.0.bn3.weight\n",
      "Load parameter layer1.0.bn3.bias\n",
      "Load parameter layer1.0.bn3.running_mean\n",
      "Load parameter layer1.0.bn3.running_var\n",
      "Load parameter layer1.0.bn3.num_batches_tracked\n",
      "Load parameter layer1.0.downsample.0.weight\n",
      "Load parameter layer1.0.downsample.1.weight\n",
      "Load parameter layer1.0.downsample.1.bias\n",
      "Load parameter layer1.0.downsample.1.running_mean\n",
      "Load parameter layer1.0.downsample.1.running_var\n",
      "Load parameter layer1.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer1.1.bn1.weight\n",
      "Load parameter layer1.1.bn1.bias\n",
      "Load parameter layer1.1.bn1.running_mean\n",
      "Load parameter layer1.1.bn1.running_var\n",
      "Load parameter layer1.1.bn1.num_batches_tracked\n",
      "Load parameter layer1.1.conv1.weight\n",
      "Load parameter layer1.1.bn2.weight\n",
      "Load parameter layer1.1.bn2.bias\n",
      "Load parameter layer1.1.bn2.running_mean\n",
      "Load parameter layer1.1.bn2.running_var\n",
      "Load parameter layer1.1.bn2.num_batches_tracked\n",
      "Load parameter layer1.1.prelu.weight\n",
      "Load parameter layer1.1.conv2.weight\n",
      "Load parameter layer1.1.bn3.weight\n",
      "Load parameter layer1.1.bn3.bias\n",
      "Load parameter layer1.1.bn3.running_mean\n",
      "Load parameter layer1.1.bn3.running_var\n",
      "Load parameter layer1.1.bn3.num_batches_tracked\n",
      "Load parameter layer1.2.bn1.weight\n",
      "Load parameter layer1.2.bn1.bias\n",
      "Load parameter layer1.2.bn1.running_mean\n",
      "Load parameter layer1.2.bn1.running_var\n",
      "Load parameter layer1.2.bn1.num_batches_tracked\n",
      "Load parameter layer1.2.conv1.weight\n",
      "Load parameter layer1.2.bn2.weight\n",
      "Load parameter layer1.2.bn2.bias\n",
      "Load parameter layer1.2.bn2.running_mean\n",
      "Load parameter layer1.2.bn2.running_var\n",
      "Load parameter layer1.2.bn2.num_batches_tracked\n",
      "Load parameter layer1.2.prelu.weight\n",
      "Load parameter layer1.2.conv2.weight\n",
      "Load parameter layer1.2.bn3.weight\n",
      "Load parameter layer1.2.bn3.bias\n",
      "Load parameter layer1.2.bn3.running_mean\n",
      "Load parameter layer1.2.bn3.running_var\n",
      "Load parameter layer1.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.bn1.weight\n",
      "Load parameter layer2.0.bn1.bias\n",
      "Load parameter layer2.0.bn1.running_mean\n",
      "Load parameter layer2.0.bn1.running_var\n",
      "Load parameter layer2.0.bn1.num_batches_tracked\n",
      "Load parameter layer2.0.conv1.weight\n",
      "Load parameter layer2.0.bn2.weight\n",
      "Load parameter layer2.0.bn2.bias\n",
      "Load parameter layer2.0.bn2.running_mean\n",
      "Load parameter layer2.0.bn2.running_var\n",
      "Load parameter layer2.0.bn2.num_batches_tracked\n",
      "Load parameter layer2.0.prelu.weight\n",
      "Load parameter layer2.0.conv2.weight\n",
      "Load parameter layer2.0.bn3.weight\n",
      "Load parameter layer2.0.bn3.bias\n",
      "Load parameter layer2.0.bn3.running_mean\n",
      "Load parameter layer2.0.bn3.running_var\n",
      "Load parameter layer2.0.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.downsample.0.weight\n",
      "Load parameter layer2.0.downsample.1.weight\n",
      "Load parameter layer2.0.downsample.1.bias\n",
      "Load parameter layer2.0.downsample.1.running_mean\n",
      "Load parameter layer2.0.downsample.1.running_var\n",
      "Load parameter layer2.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer2.1.bn1.weight\n",
      "Load parameter layer2.1.bn1.bias\n",
      "Load parameter layer2.1.bn1.running_mean\n",
      "Load parameter layer2.1.bn1.running_var\n",
      "Load parameter layer2.1.bn1.num_batches_tracked\n",
      "Load parameter layer2.1.conv1.weight\n",
      "Load parameter layer2.1.bn2.weight\n",
      "Load parameter layer2.1.bn2.bias\n",
      "Load parameter layer2.1.bn2.running_mean\n",
      "Load parameter layer2.1.bn2.running_var\n",
      "Load parameter layer2.1.bn2.num_batches_tracked\n",
      "Load parameter layer2.1.prelu.weight\n",
      "Load parameter layer2.1.conv2.weight\n",
      "Load parameter layer2.1.bn3.weight\n",
      "Load parameter layer2.1.bn3.bias\n",
      "Load parameter layer2.1.bn3.running_mean\n",
      "Load parameter layer2.1.bn3.running_var\n",
      "Load parameter layer2.1.bn3.num_batches_tracked\n",
      "Load parameter layer2.2.bn1.weight\n",
      "Load parameter layer2.2.bn1.bias\n",
      "Load parameter layer2.2.bn1.running_mean\n",
      "Load parameter layer2.2.bn1.running_var\n",
      "Load parameter layer2.2.bn1.num_batches_tracked\n",
      "Load parameter layer2.2.conv1.weight\n",
      "Load parameter layer2.2.bn2.weight\n",
      "Load parameter layer2.2.bn2.bias\n",
      "Load parameter layer2.2.bn2.running_mean\n",
      "Load parameter layer2.2.bn2.running_var\n",
      "Load parameter layer2.2.bn2.num_batches_tracked\n",
      "Load parameter layer2.2.prelu.weight\n",
      "Load parameter layer2.2.conv2.weight\n",
      "Load parameter layer2.2.bn3.weight\n",
      "Load parameter layer2.2.bn3.bias\n",
      "Load parameter layer2.2.bn3.running_mean\n",
      "Load parameter layer2.2.bn3.running_var\n",
      "Load parameter layer2.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.3.bn1.weight\n",
      "Load parameter layer2.3.bn1.bias\n",
      "Load parameter layer2.3.bn1.running_mean\n",
      "Load parameter layer2.3.bn1.running_var\n",
      "Load parameter layer2.3.bn1.num_batches_tracked\n",
      "Load parameter layer2.3.conv1.weight\n",
      "Load parameter layer2.3.bn2.weight\n",
      "Load parameter layer2.3.bn2.bias\n",
      "Load parameter layer2.3.bn2.running_mean\n",
      "Load parameter layer2.3.bn2.running_var\n",
      "Load parameter layer2.3.bn2.num_batches_tracked\n",
      "Load parameter layer2.3.prelu.weight\n",
      "Load parameter layer2.3.conv2.weight\n",
      "Load parameter layer2.3.bn3.weight\n",
      "Load parameter layer2.3.bn3.bias\n",
      "Load parameter layer2.3.bn3.running_mean\n",
      "Load parameter layer2.3.bn3.running_var\n",
      "Load parameter layer2.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.bn1.weight\n",
      "Load parameter layer3.0.bn1.bias\n",
      "Load parameter layer3.0.bn1.running_mean\n",
      "Load parameter layer3.0.bn1.running_var\n",
      "Load parameter layer3.0.bn1.num_batches_tracked\n",
      "Load parameter layer3.0.conv1.weight\n",
      "Load parameter layer3.0.bn2.weight\n",
      "Load parameter layer3.0.bn2.bias\n",
      "Load parameter layer3.0.bn2.running_mean\n",
      "Load parameter layer3.0.bn2.running_var\n",
      "Load parameter layer3.0.bn2.num_batches_tracked\n",
      "Load parameter layer3.0.prelu.weight\n",
      "Load parameter layer3.0.conv2.weight\n",
      "Load parameter layer3.0.bn3.weight\n",
      "Load parameter layer3.0.bn3.bias\n",
      "Load parameter layer3.0.bn3.running_mean\n",
      "Load parameter layer3.0.bn3.running_var\n",
      "Load parameter layer3.0.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.downsample.0.weight\n",
      "Load parameter layer3.0.downsample.1.weight\n",
      "Load parameter layer3.0.downsample.1.bias\n",
      "Load parameter layer3.0.downsample.1.running_mean\n",
      "Load parameter layer3.0.downsample.1.running_var\n",
      "Load parameter layer3.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer3.1.bn1.weight\n",
      "Load parameter layer3.1.bn1.bias\n",
      "Load parameter layer3.1.bn1.running_mean\n",
      "Load parameter layer3.1.bn1.running_var\n",
      "Load parameter layer3.1.bn1.num_batches_tracked\n",
      "Load parameter layer3.1.conv1.weight\n",
      "Load parameter layer3.1.bn2.weight\n",
      "Load parameter layer3.1.bn2.bias\n",
      "Load parameter layer3.1.bn2.running_mean\n",
      "Load parameter layer3.1.bn2.running_var\n",
      "Load parameter layer3.1.bn2.num_batches_tracked\n",
      "Load parameter layer3.1.prelu.weight\n",
      "Load parameter layer3.1.conv2.weight\n",
      "Load parameter layer3.1.bn3.weight\n",
      "Load parameter layer3.1.bn3.bias\n",
      "Load parameter layer3.1.bn3.running_mean\n",
      "Load parameter layer3.1.bn3.running_var\n",
      "Load parameter layer3.1.bn3.num_batches_tracked\n",
      "Load parameter layer3.2.bn1.weight\n",
      "Load parameter layer3.2.bn1.bias\n",
      "Load parameter layer3.2.bn1.running_mean\n",
      "Load parameter layer3.2.bn1.running_var\n",
      "Load parameter layer3.2.bn1.num_batches_tracked\n",
      "Load parameter layer3.2.conv1.weight\n",
      "Load parameter layer3.2.bn2.weight\n",
      "Load parameter layer3.2.bn2.bias\n",
      "Load parameter layer3.2.bn2.running_mean\n",
      "Load parameter layer3.2.bn2.running_var\n",
      "Load parameter layer3.2.bn2.num_batches_tracked\n",
      "Load parameter layer3.2.prelu.weight\n",
      "Load parameter layer3.2.conv2.weight\n",
      "Load parameter layer3.2.bn3.weight\n",
      "Load parameter layer3.2.bn3.bias\n",
      "Load parameter layer3.2.bn3.running_mean\n",
      "Load parameter layer3.2.bn3.running_var\n",
      "Load parameter layer3.2.bn3.num_batches_tracked\n",
      "Load parameter layer3.3.bn1.weight\n",
      "Load parameter layer3.3.bn1.bias\n",
      "Load parameter layer3.3.bn1.running_mean\n",
      "Load parameter layer3.3.bn1.running_var\n",
      "Load parameter layer3.3.bn1.num_batches_tracked\n",
      "Load parameter layer3.3.conv1.weight\n",
      "Load parameter layer3.3.bn2.weight\n",
      "Load parameter layer3.3.bn2.bias\n",
      "Load parameter layer3.3.bn2.running_mean\n",
      "Load parameter layer3.3.bn2.running_var\n",
      "Load parameter layer3.3.bn2.num_batches_tracked\n",
      "Load parameter layer3.3.prelu.weight\n",
      "Load parameter layer3.3.conv2.weight\n",
      "Load parameter layer3.3.bn3.weight\n",
      "Load parameter layer3.3.bn3.bias\n",
      "Load parameter layer3.3.bn3.running_mean\n",
      "Load parameter layer3.3.bn3.running_var\n",
      "Load parameter layer3.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.4.bn1.weight\n",
      "Load parameter layer3.4.bn1.bias\n",
      "Load parameter layer3.4.bn1.running_mean\n",
      "Load parameter layer3.4.bn1.running_var\n",
      "Load parameter layer3.4.bn1.num_batches_tracked\n",
      "Load parameter layer3.4.conv1.weight\n",
      "Load parameter layer3.4.bn2.weight\n",
      "Load parameter layer3.4.bn2.bias\n",
      "Load parameter layer3.4.bn2.running_mean\n",
      "Load parameter layer3.4.bn2.running_var\n",
      "Load parameter layer3.4.bn2.num_batches_tracked\n",
      "Load parameter layer3.4.prelu.weight\n",
      "Load parameter layer3.4.conv2.weight\n",
      "Load parameter layer3.4.bn3.weight\n",
      "Load parameter layer3.4.bn3.bias\n",
      "Load parameter layer3.4.bn3.running_mean\n",
      "Load parameter layer3.4.bn3.running_var\n",
      "Load parameter layer3.4.bn3.num_batches_tracked\n",
      "Load parameter layer3.5.bn1.weight\n",
      "Load parameter layer3.5.bn1.bias\n",
      "Load parameter layer3.5.bn1.running_mean\n",
      "Load parameter layer3.5.bn1.running_var\n",
      "Load parameter layer3.5.bn1.num_batches_tracked\n",
      "Load parameter layer3.5.conv1.weight\n",
      "Load parameter layer3.5.bn2.weight\n",
      "Load parameter layer3.5.bn2.bias\n",
      "Load parameter layer3.5.bn2.running_mean\n",
      "Load parameter layer3.5.bn2.running_var\n",
      "Load parameter layer3.5.bn2.num_batches_tracked\n",
      "Load parameter layer3.5.prelu.weight\n",
      "Load parameter layer3.5.conv2.weight\n",
      "Load parameter layer3.5.bn3.weight\n",
      "Load parameter layer3.5.bn3.bias\n",
      "Load parameter layer3.5.bn3.running_mean\n",
      "Load parameter layer3.5.bn3.running_var\n",
      "Load parameter layer3.5.bn3.num_batches_tracked\n",
      "Load parameter layer3.6.bn1.weight\n",
      "Load parameter layer3.6.bn1.bias\n",
      "Load parameter layer3.6.bn1.running_mean\n",
      "Load parameter layer3.6.bn1.running_var\n",
      "Load parameter layer3.6.bn1.num_batches_tracked\n",
      "Load parameter layer3.6.conv1.weight\n",
      "Load parameter layer3.6.bn2.weight\n",
      "Load parameter layer3.6.bn2.bias\n",
      "Load parameter layer3.6.bn2.running_mean\n",
      "Load parameter layer3.6.bn2.running_var\n",
      "Load parameter layer3.6.bn2.num_batches_tracked\n",
      "Load parameter layer3.6.prelu.weight\n",
      "Load parameter layer3.6.conv2.weight\n",
      "Load parameter layer3.6.bn3.weight\n",
      "Load parameter layer3.6.bn3.bias\n",
      "Load parameter layer3.6.bn3.running_mean\n",
      "Load parameter layer3.6.bn3.running_var\n",
      "Load parameter layer3.6.bn3.num_batches_tracked\n",
      "Load parameter layer3.7.bn1.weight\n",
      "Load parameter layer3.7.bn1.bias\n",
      "Load parameter layer3.7.bn1.running_mean\n",
      "Load parameter layer3.7.bn1.running_var\n",
      "Load parameter layer3.7.bn1.num_batches_tracked\n",
      "Load parameter layer3.7.conv1.weight\n",
      "Load parameter layer3.7.bn2.weight\n",
      "Load parameter layer3.7.bn2.bias\n",
      "Load parameter layer3.7.bn2.running_mean\n",
      "Load parameter layer3.7.bn2.running_var\n",
      "Load parameter layer3.7.bn2.num_batches_tracked\n",
      "Load parameter layer3.7.prelu.weight\n",
      "Load parameter layer3.7.conv2.weight\n",
      "Load parameter layer3.7.bn3.weight\n",
      "Load parameter layer3.7.bn3.bias\n",
      "Load parameter layer3.7.bn3.running_mean\n",
      "Load parameter layer3.7.bn3.running_var\n",
      "Load parameter layer3.7.bn3.num_batches_tracked\n",
      "Load parameter layer3.8.bn1.weight\n",
      "Load parameter layer3.8.bn1.bias\n",
      "Load parameter layer3.8.bn1.running_mean\n",
      "Load parameter layer3.8.bn1.running_var\n",
      "Load parameter layer3.8.bn1.num_batches_tracked\n",
      "Load parameter layer3.8.conv1.weight\n",
      "Load parameter layer3.8.bn2.weight\n",
      "Load parameter layer3.8.bn2.bias\n",
      "Load parameter layer3.8.bn2.running_mean\n",
      "Load parameter layer3.8.bn2.running_var\n",
      "Load parameter layer3.8.bn2.num_batches_tracked\n",
      "Load parameter layer3.8.prelu.weight\n",
      "Load parameter layer3.8.conv2.weight\n",
      "Load parameter layer3.8.bn3.weight\n",
      "Load parameter layer3.8.bn3.bias\n",
      "Load parameter layer3.8.bn3.running_mean\n",
      "Load parameter layer3.8.bn3.running_var\n",
      "Load parameter layer3.8.bn3.num_batches_tracked\n",
      "Load parameter layer3.9.bn1.weight\n",
      "Load parameter layer3.9.bn1.bias\n",
      "Load parameter layer3.9.bn1.running_mean\n",
      "Load parameter layer3.9.bn1.running_var\n",
      "Load parameter layer3.9.bn1.num_batches_tracked\n",
      "Load parameter layer3.9.conv1.weight\n",
      "Load parameter layer3.9.bn2.weight\n",
      "Load parameter layer3.9.bn2.bias\n",
      "Load parameter layer3.9.bn2.running_mean\n",
      "Load parameter layer3.9.bn2.running_var\n",
      "Load parameter layer3.9.bn2.num_batches_tracked\n",
      "Load parameter layer3.9.prelu.weight\n",
      "Load parameter layer3.9.conv2.weight\n",
      "Load parameter layer3.9.bn3.weight\n",
      "Load parameter layer3.9.bn3.bias\n",
      "Load parameter layer3.9.bn3.running_mean\n",
      "Load parameter layer3.9.bn3.running_var\n",
      "Load parameter layer3.9.bn3.num_batches_tracked\n",
      "Load parameter layer3.10.bn1.weight\n",
      "Load parameter layer3.10.bn1.bias\n",
      "Load parameter layer3.10.bn1.running_mean\n",
      "Load parameter layer3.10.bn1.running_var\n",
      "Load parameter layer3.10.bn1.num_batches_tracked\n",
      "Load parameter layer3.10.conv1.weight\n",
      "Load parameter layer3.10.bn2.weight\n",
      "Load parameter layer3.10.bn2.bias\n",
      "Load parameter layer3.10.bn2.running_mean\n",
      "Load parameter layer3.10.bn2.running_var\n",
      "Load parameter layer3.10.bn2.num_batches_tracked\n",
      "Load parameter layer3.10.prelu.weight\n",
      "Load parameter layer3.10.conv2.weight\n",
      "Load parameter layer3.10.bn3.weight\n",
      "Load parameter layer3.10.bn3.bias\n",
      "Load parameter layer3.10.bn3.running_mean\n",
      "Load parameter layer3.10.bn3.running_var\n",
      "Load parameter layer3.10.bn3.num_batches_tracked\n",
      "Load parameter layer3.11.bn1.weight\n",
      "Load parameter layer3.11.bn1.bias\n",
      "Load parameter layer3.11.bn1.running_mean\n",
      "Load parameter layer3.11.bn1.running_var\n",
      "Load parameter layer3.11.bn1.num_batches_tracked\n",
      "Load parameter layer3.11.conv1.weight\n",
      "Load parameter layer3.11.bn2.weight\n",
      "Load parameter layer3.11.bn2.bias\n",
      "Load parameter layer3.11.bn2.running_mean\n",
      "Load parameter layer3.11.bn2.running_var\n",
      "Load parameter layer3.11.bn2.num_batches_tracked\n",
      "Load parameter layer3.11.prelu.weight\n",
      "Load parameter layer3.11.conv2.weight\n",
      "Load parameter layer3.11.bn3.weight\n",
      "Load parameter layer3.11.bn3.bias\n",
      "Load parameter layer3.11.bn3.running_mean\n",
      "Load parameter layer3.11.bn3.running_var\n",
      "Load parameter layer3.11.bn3.num_batches_tracked\n",
      "Load parameter layer3.12.bn1.weight\n",
      "Load parameter layer3.12.bn1.bias\n",
      "Load parameter layer3.12.bn1.running_mean\n",
      "Load parameter layer3.12.bn1.running_var\n",
      "Load parameter layer3.12.bn1.num_batches_tracked\n",
      "Load parameter layer3.12.conv1.weight\n",
      "Load parameter layer3.12.bn2.weight\n",
      "Load parameter layer3.12.bn2.bias\n",
      "Load parameter layer3.12.bn2.running_mean\n",
      "Load parameter layer3.12.bn2.running_var\n",
      "Load parameter layer3.12.bn2.num_batches_tracked\n",
      "Load parameter layer3.12.prelu.weight\n",
      "Load parameter layer3.12.conv2.weight\n",
      "Load parameter layer3.12.bn3.weight\n",
      "Load parameter layer3.12.bn3.bias\n",
      "Load parameter layer3.12.bn3.running_mean\n",
      "Load parameter layer3.12.bn3.running_var\n",
      "Load parameter layer3.12.bn3.num_batches_tracked\n",
      "Load parameter layer3.13.bn1.weight\n",
      "Load parameter layer3.13.bn1.bias\n",
      "Load parameter layer3.13.bn1.running_mean\n",
      "Load parameter layer3.13.bn1.running_var\n",
      "Load parameter layer3.13.bn1.num_batches_tracked\n",
      "Load parameter layer3.13.conv1.weight\n",
      "Load parameter layer3.13.bn2.weight\n",
      "Load parameter layer3.13.bn2.bias\n",
      "Load parameter layer3.13.bn2.running_mean\n",
      "Load parameter layer3.13.bn2.running_var\n",
      "Load parameter layer3.13.bn2.num_batches_tracked\n",
      "Load parameter layer3.13.prelu.weight\n",
      "Load parameter layer3.13.conv2.weight\n",
      "Load parameter layer3.13.bn3.weight\n",
      "Load parameter layer3.13.bn3.bias\n",
      "Load parameter layer3.13.bn3.running_mean\n",
      "Load parameter layer3.13.bn3.running_var\n",
      "Load parameter layer3.13.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.bn1.weight\n",
      "Load parameter layer4.0.bn1.bias\n",
      "Load parameter layer4.0.bn1.running_mean\n",
      "Load parameter layer4.0.bn1.running_var\n",
      "Load parameter layer4.0.bn1.num_batches_tracked\n",
      "Load parameter layer4.0.conv1.weight\n",
      "Load parameter layer4.0.bn2.weight\n",
      "Load parameter layer4.0.bn2.bias\n",
      "Load parameter layer4.0.bn2.running_mean\n",
      "Load parameter layer4.0.bn2.running_var\n",
      "Load parameter layer4.0.bn2.num_batches_tracked\n",
      "Load parameter layer4.0.prelu.weight\n",
      "Load parameter layer4.0.conv2.weight\n",
      "Load parameter layer4.0.bn3.weight\n",
      "Load parameter layer4.0.bn3.bias\n",
      "Load parameter layer4.0.bn3.running_mean\n",
      "Load parameter layer4.0.bn3.running_var\n",
      "Load parameter layer4.0.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.downsample.0.weight\n",
      "Load parameter layer4.0.downsample.1.weight\n",
      "Load parameter layer4.0.downsample.1.bias\n",
      "Load parameter layer4.0.downsample.1.running_mean\n",
      "Load parameter layer4.0.downsample.1.running_var\n",
      "Load parameter layer4.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer4.1.bn1.weight\n",
      "Load parameter layer4.1.bn1.bias\n",
      "Load parameter layer4.1.bn1.running_mean\n",
      "Load parameter layer4.1.bn1.running_var\n",
      "Load parameter layer4.1.bn1.num_batches_tracked\n",
      "Load parameter layer4.1.conv1.weight\n",
      "Load parameter layer4.1.bn2.weight\n",
      "Load parameter layer4.1.bn2.bias\n",
      "Load parameter layer4.1.bn2.running_mean\n",
      "Load parameter layer4.1.bn2.running_var\n",
      "Load parameter layer4.1.bn2.num_batches_tracked\n",
      "Load parameter layer4.1.prelu.weight\n",
      "Load parameter layer4.1.conv2.weight\n",
      "Load parameter layer4.1.bn3.weight\n",
      "Load parameter layer4.1.bn3.bias\n",
      "Load parameter layer4.1.bn3.running_mean\n",
      "Load parameter layer4.1.bn3.running_var\n",
      "Load parameter layer4.1.bn3.num_batches_tracked\n",
      "Load parameter layer4.2.bn1.weight\n",
      "Load parameter layer4.2.bn1.bias\n",
      "Load parameter layer4.2.bn1.running_mean\n",
      "Load parameter layer4.2.bn1.running_var\n",
      "Load parameter layer4.2.bn1.num_batches_tracked\n",
      "Load parameter layer4.2.conv1.weight\n",
      "Load parameter layer4.2.bn2.weight\n",
      "Load parameter layer4.2.bn2.bias\n",
      "Load parameter layer4.2.bn2.running_mean\n",
      "Load parameter layer4.2.bn2.running_var\n",
      "Load parameter layer4.2.bn2.num_batches_tracked\n",
      "Load parameter layer4.2.prelu.weight\n",
      "Load parameter layer4.2.conv2.weight\n",
      "Load parameter layer4.2.bn3.weight\n",
      "Load parameter layer4.2.bn3.bias\n",
      "Load parameter layer4.2.bn3.running_mean\n",
      "Load parameter layer4.2.bn3.running_var\n",
      "Load parameter layer4.2.bn3.num_batches_tracked\n",
      "Load parameter bn2.weight\n",
      "Load parameter bn2.bias\n",
      "Load parameter bn2.running_mean\n",
      "Load parameter bn2.running_var\n",
      "Load parameter bn2.num_batches_tracked\n",
      "Load parameter fc.weight\n",
      "Load parameter fc.bias\n",
      "Load parameter features.weight\n",
      "Load parameter features.bias\n",
      "Load parameter features.running_mean\n",
      "Load parameter features.running_var\n",
      "Load parameter features.num_batches_tracked\n",
      "Success load pre-trained model ckpt/ArcFace-8631.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (prelu): PReLU(num_parameters=64)\n",
       "  (layer1): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): IBasicBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0, inplace=True)\n",
       "  (fc): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (features): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = iresnet50(num_classes)\n",
    "if pre_trained is not None and os.path.exists(pre_trained):\n",
    "    # No related\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_param = torch.load(pre_trained)\n",
    "    try:\n",
    "        pretrained_param = pretrained_param.state_dict()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in pretrained_param.items():\n",
    "        if k in model_dict:\n",
    "            new_state_dict[k] = v\n",
    "            print(\"Load parameter {}\".format(k))\n",
    "        elif k[7:] in model_dict:\n",
    "            new_state_dict[k[7:]] = v\n",
    "            print(\"Load parameter {}\".format(k[7:]))\n",
    "        # else:\n",
    "        #     print(\"Parameter {} unload.\".format(k[7:]))\n",
    "\n",
    "    model_dict.update(new_state_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print(\"Success load pre-trained model {}\".format(pre_trained))\n",
    "else:\n",
    "    print(\"not load pretrained\")\n",
    "\n",
    "# Set to device\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "            transforms.Resize((112,112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)\n",
    "img = transforms(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8906, -0.0348,  0.0472,  ...,  0.0828,  0.0342,  0.0935]],\n",
       "       device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  #批处理大小\n",
    "input_shape = (3, 112, 112)   #输入数据,改成自己的输入shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, *input_shape)   # 生成张量\n",
    "x = x.to(device)\n",
    "export_onnx_file = \"ArcFace-R101-8631.onnx\"\t\t# 目的ONNX文件名\n",
    "torch.onnx.export(model,\n",
    "                    x,\n",
    "                    export_onnx_file,\n",
    "                    opset_version=10,\n",
    "                    do_constant_folding=True,\t# 是否执行常量折叠优化\n",
    "                    input_names=[\"input\"],\t# 输入名\n",
    "                    output_names=[\"output\"],\t# 输出名\n",
    "                    dynamic_axes={\"input\":{0:\"batch_size\"},  # 批处理变量\n",
    "                                    \"output\":{0:\"batch_size\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:02:09.124217: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-18 16:02:09.499293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 16:02:10.611497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx_tf.backend\n",
    "import onnx\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "            transforms.Resize((112,112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"image/0001_01.jpg\"\n",
    "model_path = \"ckpt/ArcFace-R50-8631.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)\n",
    "img = np.array([transforms(img).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:02:32.070273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21733 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(model_path)\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model, device='GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:02:46.228742: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.3.2 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-04-18 16:02:46.230075: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1068 : UNIMPLEMENTED: DNN library is not found.\n",
      "2023-04-18 16:02:46.230156: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node convolution}}]]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'convolution' defined at (most recent call last):\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2504/2188837705.py\", line 1, in <module>\n      result = tf_model.run(img)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_rep.py\", line 107, in run\n      output_values = self.tf_module(**input_dict)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py\", line 97, in __call__\n      for node in self.graph_def.node:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__\n      output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 343, in _onnx_node_to_tensorflow_op\n      if handlers:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 346, in _onnx_node_to_tensorflow_op\n      if handler:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 347, in _onnx_node_to_tensorflow_op\n      return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/handler.py\", line 57, in handle\n      if ver_handle:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/handler.py\", line 59, in handle\n      return ver_handle(node, **kwargs)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv.py\", line 11, in version_1\n      return cls.conv(node, kwargs[\"tensor_dict\"])\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 137, in conv\n      if transpose:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 260, in conv\n      if depthwise is True:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 279, in conv\n      convolved = [\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 279, in conv\n      convolved = [\nNode: 'convolution'\nDNN library is not found.\n\t [[{{node convolution}}]] [Op:__inference___call___2055]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m tf_model\u001b[39m.\u001b[39;49mrun(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_rep.py:107\u001b[0m, in \u001b[0;36mTensorflowRep.run\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     input_dict[k] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(v)\n\u001b[0;32m--> 107\u001b[0m output_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtf_module(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_dict)\n\u001b[1;32m    109\u001b[0m o_values \u001b[39m=\u001b[39m []\n\u001b[1;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m o_name \u001b[39min\u001b[39;00m output_values:\n",
      "File \u001b[0;32m~/anaconda3/envs/hsic/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/hsic/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'convolution' defined at (most recent call last):\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2504/2188837705.py\", line 1, in <module>\n      result = tf_model.run(img)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_rep.py\", line 107, in run\n      output_values = self.tf_module(**input_dict)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py\", line 97, in __call__\n      for node in self.graph_def.node:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__\n      output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 343, in _onnx_node_to_tensorflow_op\n      if handlers:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 346, in _onnx_node_to_tensorflow_op\n      if handler:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/backend.py\", line 347, in _onnx_node_to_tensorflow_op\n      return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/handler.py\", line 57, in handle\n      if ver_handle:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/handler.py\", line 59, in handle\n      return ver_handle(node, **kwargs)\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv.py\", line 11, in version_1\n      return cls.conv(node, kwargs[\"tensor_dict\"])\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 137, in conv\n      if transpose:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 260, in conv\n      if depthwise is True:\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 279, in conv\n      convolved = [\n    File \"/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/onnx_tf/handlers/backend/conv_mixin.py\", line 279, in conv\n      convolved = [\nNode: 'convolution'\nDNN library is not found.\n\t [[{{node convolution}}]] [Op:__inference___call___2055]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = tf_model.run(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.argsort(result[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8906132 , -0.03505185,  0.04598166, ...,  0.08282372,\n",
       "         0.03448495,  0.09236697]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
