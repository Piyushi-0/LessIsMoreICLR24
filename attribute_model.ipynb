{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGFace2 Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from models.AttributeNet import Bottleneck, ResNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameter conv1.weight\n",
      "Load parameter bn1.weight\n",
      "Load parameter bn1.bias\n",
      "Load parameter bn1.running_mean\n",
      "Load parameter bn1.running_var\n",
      "Load parameter bn1.num_batches_tracked\n",
      "Load parameter layer1.0.conv1.weight\n",
      "Load parameter layer1.0.bn1.weight\n",
      "Load parameter layer1.0.bn1.bias\n",
      "Load parameter layer1.0.bn1.running_mean\n",
      "Load parameter layer1.0.bn1.running_var\n",
      "Load parameter layer1.0.bn1.num_batches_tracked\n",
      "Load parameter layer1.0.conv2.weight\n",
      "Load parameter layer1.0.bn2.weight\n",
      "Load parameter layer1.0.bn2.bias\n",
      "Load parameter layer1.0.bn2.running_mean\n",
      "Load parameter layer1.0.bn2.running_var\n",
      "Load parameter layer1.0.bn2.num_batches_tracked\n",
      "Load parameter layer1.0.conv3.weight\n",
      "Load parameter layer1.0.bn3.weight\n",
      "Load parameter layer1.0.bn3.bias\n",
      "Load parameter layer1.0.bn3.running_mean\n",
      "Load parameter layer1.0.bn3.running_var\n",
      "Load parameter layer1.0.bn3.num_batches_tracked\n",
      "Load parameter layer1.0.downsample.0.weight\n",
      "Load parameter layer1.0.downsample.1.weight\n",
      "Load parameter layer1.0.downsample.1.bias\n",
      "Load parameter layer1.0.downsample.1.running_mean\n",
      "Load parameter layer1.0.downsample.1.running_var\n",
      "Load parameter layer1.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer1.1.conv1.weight\n",
      "Load parameter layer1.1.bn1.weight\n",
      "Load parameter layer1.1.bn1.bias\n",
      "Load parameter layer1.1.bn1.running_mean\n",
      "Load parameter layer1.1.bn1.running_var\n",
      "Load parameter layer1.1.bn1.num_batches_tracked\n",
      "Load parameter layer1.1.conv2.weight\n",
      "Load parameter layer1.1.bn2.weight\n",
      "Load parameter layer1.1.bn2.bias\n",
      "Load parameter layer1.1.bn2.running_mean\n",
      "Load parameter layer1.1.bn2.running_var\n",
      "Load parameter layer1.1.bn2.num_batches_tracked\n",
      "Load parameter layer1.1.conv3.weight\n",
      "Load parameter layer1.1.bn3.weight\n",
      "Load parameter layer1.1.bn3.bias\n",
      "Load parameter layer1.1.bn3.running_mean\n",
      "Load parameter layer1.1.bn3.running_var\n",
      "Load parameter layer1.1.bn3.num_batches_tracked\n",
      "Load parameter layer1.2.conv1.weight\n",
      "Load parameter layer1.2.bn1.weight\n",
      "Load parameter layer1.2.bn1.bias\n",
      "Load parameter layer1.2.bn1.running_mean\n",
      "Load parameter layer1.2.bn1.running_var\n",
      "Load parameter layer1.2.bn1.num_batches_tracked\n",
      "Load parameter layer1.2.conv2.weight\n",
      "Load parameter layer1.2.bn2.weight\n",
      "Load parameter layer1.2.bn2.bias\n",
      "Load parameter layer1.2.bn2.running_mean\n",
      "Load parameter layer1.2.bn2.running_var\n",
      "Load parameter layer1.2.bn2.num_batches_tracked\n",
      "Load parameter layer1.2.conv3.weight\n",
      "Load parameter layer1.2.bn3.weight\n",
      "Load parameter layer1.2.bn3.bias\n",
      "Load parameter layer1.2.bn3.running_mean\n",
      "Load parameter layer1.2.bn3.running_var\n",
      "Load parameter layer1.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.conv1.weight\n",
      "Load parameter layer2.0.bn1.weight\n",
      "Load parameter layer2.0.bn1.bias\n",
      "Load parameter layer2.0.bn1.running_mean\n",
      "Load parameter layer2.0.bn1.running_var\n",
      "Load parameter layer2.0.bn1.num_batches_tracked\n",
      "Load parameter layer2.0.conv2.weight\n",
      "Load parameter layer2.0.bn2.weight\n",
      "Load parameter layer2.0.bn2.bias\n",
      "Load parameter layer2.0.bn2.running_mean\n",
      "Load parameter layer2.0.bn2.running_var\n",
      "Load parameter layer2.0.bn2.num_batches_tracked\n",
      "Load parameter layer2.0.conv3.weight\n",
      "Load parameter layer2.0.bn3.weight\n",
      "Load parameter layer2.0.bn3.bias\n",
      "Load parameter layer2.0.bn3.running_mean\n",
      "Load parameter layer2.0.bn3.running_var\n",
      "Load parameter layer2.0.bn3.num_batches_tracked\n",
      "Load parameter layer2.0.downsample.0.weight\n",
      "Load parameter layer2.0.downsample.1.weight\n",
      "Load parameter layer2.0.downsample.1.bias\n",
      "Load parameter layer2.0.downsample.1.running_mean\n",
      "Load parameter layer2.0.downsample.1.running_var\n",
      "Load parameter layer2.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer2.1.conv1.weight\n",
      "Load parameter layer2.1.bn1.weight\n",
      "Load parameter layer2.1.bn1.bias\n",
      "Load parameter layer2.1.bn1.running_mean\n",
      "Load parameter layer2.1.bn1.running_var\n",
      "Load parameter layer2.1.bn1.num_batches_tracked\n",
      "Load parameter layer2.1.conv2.weight\n",
      "Load parameter layer2.1.bn2.weight\n",
      "Load parameter layer2.1.bn2.bias\n",
      "Load parameter layer2.1.bn2.running_mean\n",
      "Load parameter layer2.1.bn2.running_var\n",
      "Load parameter layer2.1.bn2.num_batches_tracked\n",
      "Load parameter layer2.1.conv3.weight\n",
      "Load parameter layer2.1.bn3.weight\n",
      "Load parameter layer2.1.bn3.bias\n",
      "Load parameter layer2.1.bn3.running_mean\n",
      "Load parameter layer2.1.bn3.running_var\n",
      "Load parameter layer2.1.bn3.num_batches_tracked\n",
      "Load parameter layer2.2.conv1.weight\n",
      "Load parameter layer2.2.bn1.weight\n",
      "Load parameter layer2.2.bn1.bias\n",
      "Load parameter layer2.2.bn1.running_mean\n",
      "Load parameter layer2.2.bn1.running_var\n",
      "Load parameter layer2.2.bn1.num_batches_tracked\n",
      "Load parameter layer2.2.conv2.weight\n",
      "Load parameter layer2.2.bn2.weight\n",
      "Load parameter layer2.2.bn2.bias\n",
      "Load parameter layer2.2.bn2.running_mean\n",
      "Load parameter layer2.2.bn2.running_var\n",
      "Load parameter layer2.2.bn2.num_batches_tracked\n",
      "Load parameter layer2.2.conv3.weight\n",
      "Load parameter layer2.2.bn3.weight\n",
      "Load parameter layer2.2.bn3.bias\n",
      "Load parameter layer2.2.bn3.running_mean\n",
      "Load parameter layer2.2.bn3.running_var\n",
      "Load parameter layer2.2.bn3.num_batches_tracked\n",
      "Load parameter layer2.3.conv1.weight\n",
      "Load parameter layer2.3.bn1.weight\n",
      "Load parameter layer2.3.bn1.bias\n",
      "Load parameter layer2.3.bn1.running_mean\n",
      "Load parameter layer2.3.bn1.running_var\n",
      "Load parameter layer2.3.bn1.num_batches_tracked\n",
      "Load parameter layer2.3.conv2.weight\n",
      "Load parameter layer2.3.bn2.weight\n",
      "Load parameter layer2.3.bn2.bias\n",
      "Load parameter layer2.3.bn2.running_mean\n",
      "Load parameter layer2.3.bn2.running_var\n",
      "Load parameter layer2.3.bn2.num_batches_tracked\n",
      "Load parameter layer2.3.conv3.weight\n",
      "Load parameter layer2.3.bn3.weight\n",
      "Load parameter layer2.3.bn3.bias\n",
      "Load parameter layer2.3.bn3.running_mean\n",
      "Load parameter layer2.3.bn3.running_var\n",
      "Load parameter layer2.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.conv1.weight\n",
      "Load parameter layer3.0.bn1.weight\n",
      "Load parameter layer3.0.bn1.bias\n",
      "Load parameter layer3.0.bn1.running_mean\n",
      "Load parameter layer3.0.bn1.running_var\n",
      "Load parameter layer3.0.bn1.num_batches_tracked\n",
      "Load parameter layer3.0.conv2.weight\n",
      "Load parameter layer3.0.bn2.weight\n",
      "Load parameter layer3.0.bn2.bias\n",
      "Load parameter layer3.0.bn2.running_mean\n",
      "Load parameter layer3.0.bn2.running_var\n",
      "Load parameter layer3.0.bn2.num_batches_tracked\n",
      "Load parameter layer3.0.conv3.weight\n",
      "Load parameter layer3.0.bn3.weight\n",
      "Load parameter layer3.0.bn3.bias\n",
      "Load parameter layer3.0.bn3.running_mean\n",
      "Load parameter layer3.0.bn3.running_var\n",
      "Load parameter layer3.0.bn3.num_batches_tracked\n",
      "Load parameter layer3.0.downsample.0.weight\n",
      "Load parameter layer3.0.downsample.1.weight\n",
      "Load parameter layer3.0.downsample.1.bias\n",
      "Load parameter layer3.0.downsample.1.running_mean\n",
      "Load parameter layer3.0.downsample.1.running_var\n",
      "Load parameter layer3.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer3.1.conv1.weight\n",
      "Load parameter layer3.1.bn1.weight\n",
      "Load parameter layer3.1.bn1.bias\n",
      "Load parameter layer3.1.bn1.running_mean\n",
      "Load parameter layer3.1.bn1.running_var\n",
      "Load parameter layer3.1.bn1.num_batches_tracked\n",
      "Load parameter layer3.1.conv2.weight\n",
      "Load parameter layer3.1.bn2.weight\n",
      "Load parameter layer3.1.bn2.bias\n",
      "Load parameter layer3.1.bn2.running_mean\n",
      "Load parameter layer3.1.bn2.running_var\n",
      "Load parameter layer3.1.bn2.num_batches_tracked\n",
      "Load parameter layer3.1.conv3.weight\n",
      "Load parameter layer3.1.bn3.weight\n",
      "Load parameter layer3.1.bn3.bias\n",
      "Load parameter layer3.1.bn3.running_mean\n",
      "Load parameter layer3.1.bn3.running_var\n",
      "Load parameter layer3.1.bn3.num_batches_tracked\n",
      "Load parameter layer3.2.conv1.weight\n",
      "Load parameter layer3.2.bn1.weight\n",
      "Load parameter layer3.2.bn1.bias\n",
      "Load parameter layer3.2.bn1.running_mean\n",
      "Load parameter layer3.2.bn1.running_var\n",
      "Load parameter layer3.2.bn1.num_batches_tracked\n",
      "Load parameter layer3.2.conv2.weight\n",
      "Load parameter layer3.2.bn2.weight\n",
      "Load parameter layer3.2.bn2.bias\n",
      "Load parameter layer3.2.bn2.running_mean\n",
      "Load parameter layer3.2.bn2.running_var\n",
      "Load parameter layer3.2.bn2.num_batches_tracked\n",
      "Load parameter layer3.2.conv3.weight\n",
      "Load parameter layer3.2.bn3.weight\n",
      "Load parameter layer3.2.bn3.bias\n",
      "Load parameter layer3.2.bn3.running_mean\n",
      "Load parameter layer3.2.bn3.running_var\n",
      "Load parameter layer3.2.bn3.num_batches_tracked\n",
      "Load parameter layer3.3.conv1.weight\n",
      "Load parameter layer3.3.bn1.weight\n",
      "Load parameter layer3.3.bn1.bias\n",
      "Load parameter layer3.3.bn1.running_mean\n",
      "Load parameter layer3.3.bn1.running_var\n",
      "Load parameter layer3.3.bn1.num_batches_tracked\n",
      "Load parameter layer3.3.conv2.weight\n",
      "Load parameter layer3.3.bn2.weight\n",
      "Load parameter layer3.3.bn2.bias\n",
      "Load parameter layer3.3.bn2.running_mean\n",
      "Load parameter layer3.3.bn2.running_var\n",
      "Load parameter layer3.3.bn2.num_batches_tracked\n",
      "Load parameter layer3.3.conv3.weight\n",
      "Load parameter layer3.3.bn3.weight\n",
      "Load parameter layer3.3.bn3.bias\n",
      "Load parameter layer3.3.bn3.running_mean\n",
      "Load parameter layer3.3.bn3.running_var\n",
      "Load parameter layer3.3.bn3.num_batches_tracked\n",
      "Load parameter layer3.4.conv1.weight\n",
      "Load parameter layer3.4.bn1.weight\n",
      "Load parameter layer3.4.bn1.bias\n",
      "Load parameter layer3.4.bn1.running_mean\n",
      "Load parameter layer3.4.bn1.running_var\n",
      "Load parameter layer3.4.bn1.num_batches_tracked\n",
      "Load parameter layer3.4.conv2.weight\n",
      "Load parameter layer3.4.bn2.weight\n",
      "Load parameter layer3.4.bn2.bias\n",
      "Load parameter layer3.4.bn2.running_mean\n",
      "Load parameter layer3.4.bn2.running_var\n",
      "Load parameter layer3.4.bn2.num_batches_tracked\n",
      "Load parameter layer3.4.conv3.weight\n",
      "Load parameter layer3.4.bn3.weight\n",
      "Load parameter layer3.4.bn3.bias\n",
      "Load parameter layer3.4.bn3.running_mean\n",
      "Load parameter layer3.4.bn3.running_var\n",
      "Load parameter layer3.4.bn3.num_batches_tracked\n",
      "Load parameter layer3.5.conv1.weight\n",
      "Load parameter layer3.5.bn1.weight\n",
      "Load parameter layer3.5.bn1.bias\n",
      "Load parameter layer3.5.bn1.running_mean\n",
      "Load parameter layer3.5.bn1.running_var\n",
      "Load parameter layer3.5.bn1.num_batches_tracked\n",
      "Load parameter layer3.5.conv2.weight\n",
      "Load parameter layer3.5.bn2.weight\n",
      "Load parameter layer3.5.bn2.bias\n",
      "Load parameter layer3.5.bn2.running_mean\n",
      "Load parameter layer3.5.bn2.running_var\n",
      "Load parameter layer3.5.bn2.num_batches_tracked\n",
      "Load parameter layer3.5.conv3.weight\n",
      "Load parameter layer3.5.bn3.weight\n",
      "Load parameter layer3.5.bn3.bias\n",
      "Load parameter layer3.5.bn3.running_mean\n",
      "Load parameter layer3.5.bn3.running_var\n",
      "Load parameter layer3.5.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.conv1.weight\n",
      "Load parameter layer4.0.bn1.weight\n",
      "Load parameter layer4.0.bn1.bias\n",
      "Load parameter layer4.0.bn1.running_mean\n",
      "Load parameter layer4.0.bn1.running_var\n",
      "Load parameter layer4.0.bn1.num_batches_tracked\n",
      "Load parameter layer4.0.conv2.weight\n",
      "Load parameter layer4.0.bn2.weight\n",
      "Load parameter layer4.0.bn2.bias\n",
      "Load parameter layer4.0.bn2.running_mean\n",
      "Load parameter layer4.0.bn2.running_var\n",
      "Load parameter layer4.0.bn2.num_batches_tracked\n",
      "Load parameter layer4.0.conv3.weight\n",
      "Load parameter layer4.0.bn3.weight\n",
      "Load parameter layer4.0.bn3.bias\n",
      "Load parameter layer4.0.bn3.running_mean\n",
      "Load parameter layer4.0.bn3.running_var\n",
      "Load parameter layer4.0.bn3.num_batches_tracked\n",
      "Load parameter layer4.0.downsample.0.weight\n",
      "Load parameter layer4.0.downsample.1.weight\n",
      "Load parameter layer4.0.downsample.1.bias\n",
      "Load parameter layer4.0.downsample.1.running_mean\n",
      "Load parameter layer4.0.downsample.1.running_var\n",
      "Load parameter layer4.0.downsample.1.num_batches_tracked\n",
      "Load parameter layer4.1.conv1.weight\n",
      "Load parameter layer4.1.bn1.weight\n",
      "Load parameter layer4.1.bn1.bias\n",
      "Load parameter layer4.1.bn1.running_mean\n",
      "Load parameter layer4.1.bn1.running_var\n",
      "Load parameter layer4.1.bn1.num_batches_tracked\n",
      "Load parameter layer4.1.conv2.weight\n",
      "Load parameter layer4.1.bn2.weight\n",
      "Load parameter layer4.1.bn2.bias\n",
      "Load parameter layer4.1.bn2.running_mean\n",
      "Load parameter layer4.1.bn2.running_var\n",
      "Load parameter layer4.1.bn2.num_batches_tracked\n",
      "Load parameter layer4.1.conv3.weight\n",
      "Load parameter layer4.1.bn3.weight\n",
      "Load parameter layer4.1.bn3.bias\n",
      "Load parameter layer4.1.bn3.running_mean\n",
      "Load parameter layer4.1.bn3.running_var\n",
      "Load parameter layer4.1.bn3.num_batches_tracked\n",
      "Load parameter layer4.2.conv1.weight\n",
      "Load parameter layer4.2.bn1.weight\n",
      "Load parameter layer4.2.bn1.bias\n",
      "Load parameter layer4.2.bn1.running_mean\n",
      "Load parameter layer4.2.bn1.running_var\n",
      "Load parameter layer4.2.bn1.num_batches_tracked\n",
      "Load parameter layer4.2.conv2.weight\n",
      "Load parameter layer4.2.bn2.weight\n",
      "Load parameter layer4.2.bn2.bias\n",
      "Load parameter layer4.2.bn2.running_mean\n",
      "Load parameter layer4.2.bn2.running_var\n",
      "Load parameter layer4.2.bn2.num_batches_tracked\n",
      "Load parameter layer4.2.conv3.weight\n",
      "Load parameter layer4.2.bn3.weight\n",
      "Load parameter layer4.2.bn3.bias\n",
      "Load parameter layer4.2.bn3.running_mean\n",
      "Load parameter layer4.2.bn3.running_var\n",
      "Load parameter layer4.2.bn3.num_batches_tracked\n",
      "Load parameter fc1.weight\n",
      "Load parameter fc1.bias\n",
      "Load parameter fc2.weight\n",
      "Load parameter fc2.bias\n",
      "Load parameter fc3.weight\n",
      "Load parameter fc3.bias\n",
      "Load parameter fc4.weight\n",
      "Load parameter fc4.bias\n",
      "Load parameter fc5.weight\n",
      "Load parameter fc5.bias\n",
      "Load parameter fc6.weight\n",
      "Load parameter fc6.bias\n",
      "Load parameter fc7.weight\n",
      "Load parameter fc7.bias\n",
      "Load parameter fc8.weight\n",
      "Load parameter fc8.bias\n",
      "Load parameter fc9.weight\n",
      "Load parameter fc9.bias\n",
      "Load parameter fc10.weight\n",
      "Load parameter fc10.bias\n",
      "Load parameter fc11.weight\n",
      "Load parameter fc11.bias\n",
      "Load parameter fc12.weight\n",
      "Load parameter fc12.bias\n",
      "Load parameter fc13.weight\n",
      "Load parameter fc13.bias\n",
      "Load parameter fc14.weight\n",
      "Load parameter fc14.bias\n",
      "Load parameter fc15.weight\n",
      "Load parameter fc15.bias\n",
      "Load parameter fc16.weight\n",
      "Load parameter fc16.bias\n",
      "Load parameter fc17.weight\n",
      "Load parameter fc17.bias\n",
      "Load parameter fc18.weight\n",
      "Load parameter fc18.bias\n",
      "Load parameter fc19.weight\n",
      "Load parameter fc19.bias\n",
      "Load parameter fc20.weight\n",
      "Load parameter fc20.bias\n",
      "Load parameter fc21.weight\n",
      "Load parameter fc21.bias\n",
      "Load parameter fc22.weight\n",
      "Load parameter fc22.bias\n",
      "Load parameter fc23.weight\n",
      "Load parameter fc23.bias\n",
      "Load parameter fc24.weight\n",
      "Load parameter fc24.bias\n",
      "Load parameter fc25.weight\n",
      "Load parameter fc25.bias\n",
      "Load parameter fc26.weight\n",
      "Load parameter fc26.bias\n",
      "Load parameter fc27.weight\n",
      "Load parameter fc27.bias\n",
      "Load parameter fc28.weight\n",
      "Load parameter fc28.bias\n",
      "Load parameter fc29.weight\n",
      "Load parameter fc29.bias\n",
      "Load parameter fc30.weight\n",
      "Load parameter fc30.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc1): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc4): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc5): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc6): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc7): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc8): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc9): Linear(in_features=2048, out_features=5, bias=True)\n",
       "  (fc10): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc11): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc12): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc13): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc14): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc15): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc16): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc17): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc18): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc19): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc20): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc21): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc22): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc23): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc24): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc25): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc26): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc27): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc28): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc29): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc30): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "pretrained = \"ckpt/AttributeNet-VGGFace2.pkl\"\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "pretrained_param = torch.load(pretrained, map_location=torch.device('cpu'))\n",
    "try:\n",
    "    pretrained_param = pretrained_param.state_dict()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in pretrained_param.items():\n",
    "    if k in model_dict:\n",
    "        new_state_dict[k] = v\n",
    "        print(\"Load parameter {}\".format(k))\n",
    "    elif k[7:] in model_dict:\n",
    "        new_state_dict[k[7:]] = v\n",
    "        print(\"Load parameter {}\".format(k[7:]))\n",
    "\n",
    "model_dict.update(new_state_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "# model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Path_Image_Preprocessing(path):\n",
    "    '''\n",
    "    Precessing the input images\n",
    "        image_dir: single image input path, such as \"/home/xxx/10.jpg\"\n",
    "    '''\n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])\n",
    "    image = cv2.imread(path)\n",
    "    assert image is not None\n",
    "    image = cv2.resize(image,(224,224))\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean_bgr\n",
    "    # H * W * C   -->   C * H * W\n",
    "    image = image.transpose(2,0,1)\n",
    "    image = torch.tensor(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"image/0001_01.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Path_Image_Preprocessing(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc1): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc4): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc5): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc6): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc7): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc8): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc9): Linear(in_features=2048, out_features=5, bias=True)\n",
       "  (fc10): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc11): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc12): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc13): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (fc14): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc15): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc16): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc17): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc18): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc19): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc20): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc21): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc22): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc23): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc24): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc25): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc26): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc27): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc28): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc29): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (fc30): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-3.2464,  3.2464]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 5.0319, -2.6858, -2.3416]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.0106,  4.3319, -2.3362]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.9176,  5.1455, -2.2221]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 3.2828, -2.8861, -0.4020]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-4.0965,  5.1140, -0.9972]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 3.6238, -3.0235, -0.6040]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.3789,  4.8772, -2.5455]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.0208,  0.9672,  2.3222, -3.2441,  1.9985]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 3.7580, -3.7579]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.8646,  3.8646]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.6931,  3.6932]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.6397,  3.6397]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.5726, -3.1266,  2.5577]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.1476,  5.1608, -3.0297]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.5105,  2.3965,  1.0180]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.9494,  4.6000, -1.6475]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.2877, -1.8113,  1.5259]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.0792,  4.6992, -1.6174]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.6058,  0.8596,  1.7705]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.9026,  2.5061,  0.3862]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.6975,  1.7334,  1.9388]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.3946,  3.4937, -0.0758]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.7414,  4.6382, -1.9217]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 2.7527, -2.7969,  0.0410]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-2.1877, -1.2288,  3.4321]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.5573, -1.3526,  1.9100]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 2.0591, -3.0587,  1.0010]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-4.1399,  3.4339,  0.7034]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 3.9988, -1.6065, -2.3933]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  #批处理大小\n",
    "input_shape = (3, 224, 224)   #输入数据,改成自己的输入shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, *input_shape)   # 生成张量\n",
    "x = x.cuda()\n",
    "export_onnx_file = \"ckpt/AttributeNet-VGGFace2.onnx\"\t\t# 目的ONNX文件名\n",
    "torch.onnx.export(model,\n",
    "                    x,\n",
    "                    export_onnx_file,\n",
    "                    opset_version=10,\n",
    "                    do_constant_folding=True,\t# 是否执行常量折叠优化\n",
    "                    input_names=[\"input\"],\t# 输入名\n",
    "                    output_names=[\"output\"],\t# 输出名\n",
    "                    dynamic_axes={\"input\":{0:\"batch_size\"},  # 批处理变量\n",
    "                                    \"output\":{0:\"batch_size\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VggFace2 Attribute ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:12:02.092670: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-18 20:12:02.137522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 20:12:02.866079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx_tf.backend\n",
    "import onnx\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Path_Image_Preprocessing(path):\n",
    "    '''\n",
    "    Precessing the input images\n",
    "        image_dir: single image input path, such as \"/home/xxx/10.jpg\"\n",
    "    '''\n",
    "    mean_bgr = np.array([91.4953, 103.8827, 131.0912])\n",
    "    image = cv2.imread(path)\n",
    "    assert image is not None\n",
    "    image = cv2.resize(image,(224,224))\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean_bgr\n",
    "    # H * W * C   -->   C * H * W\n",
    "    image = image.transpose(2,0,1)\n",
    "    image = np.array([image, image, image, image])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"image/0001_01.jpg\"\n",
    "model_path = \"ckpt/AttributeNet-VGGFace2.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Path_Image_Preprocessing(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:12:13.740384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21725 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(model_path)\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model, device='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:12:24.067119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-18 20:12:24.816126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "result = tf_model.run(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\n",
    "    [result[0][:,1]],\n",
    "    [result[0][:,1]],\n",
    "    [result[0][:,1]],\n",
    "    ]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = result[0][:,1][:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.249253, 2.249253],\n",
       "       [3.249253, 2.249253]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(x, x-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.249878, 2.249878],\n",
       "       [3.249878, 2.249878],\n",
       "       [3.249878, 2.249878],\n",
       "       [3.249878, 2.249878]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.append(x, x-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.249253],\n",
       "       [2.249253]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(2, 0), dtype=float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = [[] for i in range(2)]\n",
    "np.array(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celeb-A AttributeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cry/anaconda3/envs/hsic/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from models.BranchedTiny import BranchedTinyAttr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_net = BranchedTinyAttr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(img, size):\n",
    "    if type(size) == tuple:\n",
    "        assert size[0] == size[1]\n",
    "        size = size[0]\n",
    "\n",
    "    orig_size = img.size(3)\n",
    "    if size < orig_size:\n",
    "        mode = 'area'\n",
    "    else:\n",
    "        mode = 'bilinear'\n",
    "    return F.interpolate(img, (size, size), mode=mode)\n",
    "\n",
    "def read_img(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img = TF.to_tensor(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    if img.size(-1) != 224:\n",
    "        img = interpolate(img, 224)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"image/n000002-0001_01.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_net.set_idx_list(['male', 'young',\n",
    "    'arched_eyebrows', 'bushy_eyebrows',\n",
    "    'mouth_slightly_open', 'big_lips',\n",
    "    'big_nose', 'pointy_nose',\n",
    "    'bags_under_eyes', 'narrow_eyes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = read_img(img_path)\n",
    "predicted = attribute_net(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9536,  4.8605, -0.7729, -3.5993, -1.5853, -1.6258, -4.3598, -1.3096,\n",
       "         -3.4509, -3.9110]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  #批处理大小\n",
    "input_shape = (3, 224, 224)   #输入数据,改成自己的输入shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, *input_shape)   # 生成张量\n",
    "x = x.cuda()\n",
    "export_onnx_file = \"ckpt/AttributeNet-CelebA.onnx\"\t\t# 目的ONNX文件名\n",
    "torch.onnx.export(attribute_net.cuda(),\n",
    "                    x,\n",
    "                    export_onnx_file,\n",
    "                    opset_version=10,\n",
    "                    do_constant_folding=True,\t# 是否执行常量折叠优化\n",
    "                    input_names=[\"input\"],\t# 输入名\n",
    "                    output_names=[\"output\"],\t# 输出名\n",
    "                    dynamic_axes={\"input\":{0:\"batch_size\"},  # 批处理变量\n",
    "                                    \"output\":{0:\"batch_size\"}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celeb-A Attribute ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_tf.backend\n",
    "import onnx\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(img, size):\n",
    "    if type(size) == tuple:\n",
    "        assert size[0] == size[1]\n",
    "        size = size[0]\n",
    "\n",
    "    orig_size = img.size(3)\n",
    "    if size < orig_size:\n",
    "        mode = 'area'\n",
    "    else:\n",
    "        mode = 'bilinear'\n",
    "    return F.interpolate(img, (size, size), mode=mode)\n",
    "\n",
    "def read_img(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img = TF.to_tensor(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    if img.size(-1) != 224:\n",
    "        img = interpolate(img, 224)\n",
    "    return img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"image/n000002-0001_01.jpg\"\n",
    "model_path = \"ckpt/AttributeNet-CelebA.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:51:26.476769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21761 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(model_path)\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model, device='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_img(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_model.run(np.array([img[0], img[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.860705, 3.860705],\n",
       "       [4.860705, 3.860705]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(result[0][:,1][:, np.newaxis],\n",
    "          result[0][:,1][:, np.newaxis] -1, 1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
